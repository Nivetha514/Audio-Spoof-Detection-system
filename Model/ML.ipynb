{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define paths to your CSV datasets\n",
    "dataset1_path = \"DATASET-balanced.csv\"\n",
    "dataset2_path = \"DATASET-LA.csv\"\n",
    "\n",
    "# Read data from CSV files\n",
    "df1 = pd.read_csv(dataset1_path)\n",
    "df2 = pd.read_csv(dataset2_path)\n",
    "# Define desired size for datasets\n",
    "target_size = 1000 \n",
    "\n",
    "# Stratified sampling to maintain class balance\n",
    "smaller_df = df1.sample(target_size, random_state=42) \n",
    "larger_df = df2.sample(target_size, random_state=42)\n",
    "\n",
    "# Combine features and labels from both datasets\n",
    "features1 = smaller_df.drop(\"Classname\", axis=1)\n",
    "features2 = larger_df.drop(\"Classname\", axis=1)\n",
    "labels1 = smaller_df[\"Classname\"]\n",
    "labels2 =larger_df[\"Classname\"]\n",
    "\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(features1, labels1, test_size=0.2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(features2, labels2, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.9550\n",
      "Ensemble accuracy2: 0.8950\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define two machine learning models \n",
    "model1 = RandomForestClassifier()\n",
    "model2 = RandomForestClassifier()\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train1_encoded = le.fit_transform(y_train1)\n",
    "y_train2_encoded = le.fit_transform(y_train2)\n",
    "\n",
    "# Train models with encoded labels\n",
    "model1.fit(X_train1, y_train1_encoded)\n",
    "model2.fit(X_train2, y_train2_encoded)\n",
    "\n",
    "estimators = [\n",
    "    (\"model1\", model1),\n",
    "    (\"model2\", model2),\n",
    "]\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "\n",
    "voting_classifier.fit(X_train1, y_train1)\n",
    "\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions = voting_classifier.predict(X_test1)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy = accuracy_score(y_test1, voting_predictions)\n",
    "print(f\"Ensemble accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "voting_classifier2 = VotingClassifier(estimators=estimators, voting=\"soft\")  # Choose voting strategy\n",
    "\n",
    "voting_classifier2.fit(X_train2, y_train2)\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions2 = voting_classifier2.predict(X_test2)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy2 = accuracy_score(y_test2, voting_predictions2)\n",
    "print(f\"Ensemble accuracy2: {accuracy2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision1: 0.9101\n",
      "Recall1: 0.9878048780487805\n",
      "Precision2: 0.8994974874371859\n",
      "Recall2: 0.9944444444444445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "precision1 = precision_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "recall1 = recall_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "\n",
    "print(f'Precision1: {precision1:.4f}')\n",
    "print(f'Recall1: {recall1}')\n",
    "\n",
    "\n",
    "precision2 = precision_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "recall2 = recall_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "\n",
    "print(f'Precision2: {precision2}')\n",
    "print(f'Recall2: {recall2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Random Forest : 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.9750\n",
      "Ensemble accuracy2: 0.8950\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define two machine learning models \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "model1 = RandomForestClassifier()\n",
    "model2 = HistGradientBoostingClassifier()\n",
    "\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train1_encoded = le.fit_transform(y_train1)\n",
    "y_train2_encoded = le.fit_transform(y_train2)\n",
    "\n",
    "# Train models with encoded labels\n",
    "model1.fit(X_train1, y_train1_encoded)\n",
    "model2.fit(X_train2, y_train2_encoded)\n",
    "\n",
    "estimators = [\n",
    "    (\"model1\", model1),\n",
    "    (\"model2\", model2),\n",
    "]\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "\n",
    "voting_classifier.fit(X_train1, y_train1)\n",
    "\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions = voting_classifier.predict(X_test1)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy = accuracy_score(y_test1, voting_predictions)\n",
    "print(f\"Ensemble accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "voting_classifier2 = VotingClassifier(estimators=estimators, voting=\"soft\")  # Choose voting strategy\n",
    "\n",
    "voting_classifier2.fit(X_train2, y_train2)\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions2 = voting_classifier2.predict(X_test2)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy2 = accuracy_score(y_test2, voting_predictions2)\n",
    "print(f\"Ensemble accuracy2: {accuracy2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision1: 0.9529\n",
      "Recall1: 0.9878048780487805\n",
      "Precision2: 0.8994974874371859\n",
      "Recall2: 0.9944444444444445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "precision1 = precision_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "recall1 = recall_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "\n",
    "print(f'Precision1: {precision1:.4f}')\n",
    "print(f'Recall1: {recall1}')\n",
    "\n",
    "\n",
    "precision2 = precision_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "recall2 = recall_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "\n",
    "print(f'Precision2: {precision2}')\n",
    "print(f'Recall2: {recall2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest + HistGradientBoostingClassifier : 95.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.9550\n",
      "Ensemble accuracy2: 0.9000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "model1 = RandomForestClassifier()\n",
    "model2 = HistGradientBoostingClassifier()\n",
    "model3 = SVC(probability=True)\n",
    "model4 = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train1_encoded = le.fit_transform(y_train1)\n",
    "y_train2_encoded = le.fit_transform(y_train2)\n",
    "\n",
    "# Train models with encoded labels\n",
    "model1.fit(X_train1, y_train1_encoded)\n",
    "model2.fit(X_train2, y_train2_encoded)\n",
    "model3.fit(X_train2, y_train2_encoded)\n",
    "model4.fit(X_train1, y_train1_encoded)\n",
    "\n",
    "estimators = [\n",
    "    (\"model1\", model1),\n",
    "    (\"model2\", model2),\n",
    "    (\"model3\", model3),\n",
    "    (\"model4\",model4)\n",
    "]\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "\n",
    "voting_classifier.fit(X_train1, y_train1)\n",
    "\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions = voting_classifier.predict(X_test1)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy = accuracy_score(y_test1, voting_predictions)\n",
    "print(f\"Ensemble accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "voting_classifier2 = VotingClassifier(estimators=estimators, voting=\"soft\")  # Choose your voting strategy\n",
    "\n",
    "voting_classifier2.fit(X_train2, y_train2)\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions2 = voting_classifier2.predict(X_test2)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy2 = accuracy_score(y_test2, voting_predictions2)\n",
    "print(f\"Ensemble accuracy2: {accuracy2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision1: 0.9195\n",
      "Recall1: 0.975609756097561\n",
      "Precision2: 0.9\n",
      "Recall2: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "precision1 = precision_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "recall1 = recall_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "\n",
    "print(f'Precision1: {precision1:.4f}')\n",
    "print(f'Recall1: {recall1}')\n",
    "\n",
    "\n",
    "precision2 = precision_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "recall2 = recall_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "\n",
    "print(f'Precision2: {precision2}')\n",
    "print(f'Recall2: {recall2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.8650\n",
      "Ensemble accuracy2: 0.7850\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define two machine learning models \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = DecisionTreeClassifier()\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train1_encoded = le.fit_transform(y_train1)\n",
    "y_train2_encoded = le.fit_transform(y_train2)\n",
    "\n",
    "# Train models with encoded labels\n",
    "model1.fit(X_train1, y_train1_encoded)\n",
    "model2.fit(X_train2, y_train2_encoded)\n",
    "\n",
    "estimators = [\n",
    "    (\"model1\", model1),\n",
    "    (\"model2\", model2),\n",
    "]\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "\n",
    "voting_classifier.fit(X_train1, y_train1)\n",
    "\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions = voting_classifier.predict(X_test1)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy = accuracy_score(y_test1, voting_predictions)\n",
    "print(f\"Ensemble accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "voting_classifier2 = VotingClassifier(estimators=estimators, voting=\"soft\")  # Choose voting strategy\n",
    "\n",
    "voting_classifier2.fit(X_train2, y_train2)\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions2 = voting_classifier2.predict(X_test2)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy2 = accuracy_score(y_test2, voting_predictions2)\n",
    "print(f\"Ensemble accuracy2: {accuracy2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision1: 0.8090\n",
      "Recall1: 0.8780487804878049\n",
      "Precision2: 0.8914285714285715\n",
      "Recall2: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "precision1 = precision_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "recall1 = recall_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "\n",
    "print(f'Precision1: {precision1:.4f}')\n",
    "print(f'Recall1: {recall1}')\n",
    "\n",
    "\n",
    "precision2 = precision_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "recall2 = recall_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "\n",
    "print(f'Precision2: {precision2}')\n",
    "print(f'Recall2: {recall2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 0.6450\n",
      "Ensemble accuracy2: 0.9000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model1 = SVC(probability=True)\n",
    "model2 = KNeighborsClassifier()\n",
    "\n",
    "\n",
    "# Encode labels using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train1_encoded = le.fit_transform(y_train1)\n",
    "y_train2_encoded = le.fit_transform(y_train2)\n",
    "\n",
    "# Train models with encoded labels\n",
    "model1.fit(X_train1, y_train1_encoded)\n",
    "model2.fit(X_train2, y_train2_encoded)\n",
    "\n",
    "estimators = [\n",
    "    (\"model1\", model1),\n",
    "    (\"model2\", model2)\n",
    "]\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=estimators, voting=\"soft\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "\n",
    "voting_classifier.fit(X_train1, y_train1)\n",
    "\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions = voting_classifier.predict(X_test1)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy = accuracy_score(y_test1, voting_predictions)\n",
    "print(f\"Ensemble accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Create a voting classifier ensemble\n",
    "voting_classifier2 = VotingClassifier(estimators=estimators, voting=\"soft\")  # Choose your voting strategy\n",
    "\n",
    "voting_classifier2.fit(X_train2, y_train2)\n",
    "# Make predictions on the test set using the ensemble\n",
    "voting_predictions2 = voting_classifier2.predict(X_test2)\n",
    "\n",
    "# Evaluate the accuracy of the ensemble model\n",
    "accuracy2 = accuracy_score(y_test2, voting_predictions2)\n",
    "print(f\"Ensemble accuracy2: {accuracy2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision1: 0.5495\n",
      "Recall1: 0.7439024390243902\n",
      "Precision2: 0.9\n",
      "Recall2: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "precision1 = precision_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "recall1 = recall_score(y_test1, voting_predictions, average='binary', pos_label='FAKE')\n",
    "\n",
    "print(f'Precision1: {precision1:.4f}')\n",
    "print(f'Recall1: {recall1}')\n",
    "\n",
    "\n",
    "precision2 = precision_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "recall2 = recall_score(y_test2, voting_predictions2, average='binary', pos_label='spoof')\n",
    "\n",
    "print(f'Precision2: {precision2}')\n",
    "print(f'Recall2: {recall2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
